# FPGA创新设计大赛 AMD赛道命题式赛道 - 设计报告


## 1. 项目概述

### 1.1 项目背景
项目一：本项目是“嵌赛FPGA赛道-AMD 命题式基础赛道”的初赛题目之一。竞赛要求基于 Vitis HLS 2024.2 工具，针对 Vitis Libraries 中的 SHA-256 算法进行深度优化。SHA-256 作为一种广泛应用的加密哈希函数，其在硬件上的高效实现对于安全、区块链等领域的FPGA加速应用至关重要。

项目二：本项目针对2025年全国大学生嵌入式芯片与系统设计竞赛的“FPGA创新设计大赛-AMD赛道-命题式基础赛道”中的题目二：LZ4 Compress 算法进行高层次综合（HLS）优化。
LZ4是一种广泛应用的、以极高压缩和解压速度著称的无损数据压缩算法，其硬件化实现对于提升数据中心、网络传输等场景的吞吐率具有重要意义。

项目三：本项目是“嵌赛FPGA赛道-AMD 命题式基础赛道”的初赛题目之一。竞赛要求基于 Vitis HLS 2024.2 工具，针对 Vitis Libraries 中的 Cholesky (Complex Fixed-Point, ARCH0) 算法进行深度优化。Cholesky 分解在信号处理、最小二乘求解、贝叶斯估计与机器学习中的协方差矩阵分解等场景被广泛使用，其在硬件上的高效实现对于嵌入式加速平台（如 Zynq-7000）具有重要意义。

### 1.2 设计目标

根据竞赛评分规则，本项目的核心优化目标是最小化算法的最终执行时间（Execution Time），同时必须满足以下约束条件：

功能正确性：优化后的设计必须通过C仿真和C/RTL协同仿真，且输出结果与原始实现完全一致。
时序收敛：在尽可能高的时钟频率下实现时序满足（Slack > 0），或在时序违例但总分更高的情况下做出权衡。
资源可实现：所有资源使用量（LUT, FF, BRAM, DSP）必须在目标器件 xc7z020-clg484-1 的容量范围内。


### 1.3 技术规格

- **目标平台：** AMD PYNQ-Z2
- **开发工具：** Vitis HLS 2024.2
- **编程语言：** C++/HLS
- **验证环境：** Vitis HLS C-Simulation 与 C/RTL Co-simulation

---

## 2. 设计原理和功能框图

### 2.1 算法原理
项目一：
    SHA-256 算法接收任意长度的输入消息，并产生一个256位的固定长度哈希值。其核心处理流程包括：

    消息填充 (Padding)：对输入消息进行填充，使其总长度为512位的整数倍。填充包括附加一个 '1' bit，若干 '0' bit，以及一个64位的消息原始长度。

    分块处理：将填充后的消息分割成若干个512位（64字节）的消息块。

    迭代压缩：使用8个32位的哈希初值（H0-H7）开始，对每个消息块进行迭代压缩。压缩过程包含64轮复杂的逻辑和算术运算。

    消息调度 (Message Schedule)：每轮计算前，需要根据当前消息块生成一个32位的字 Wt。前16个 Wt 直接来自消息块，后48个 Wt 通过如下公式递归生成：
    
    轮函数 ：每轮更新8个工作变量(a, b, c, d, e, f, g, h)，其核心计算公式为：
    
    最终哈希值：处理完所有消息块后，将每轮压缩更新的哈希值与初始哈希值相加，得到最终的256位摘要。

项目二：
    
// LZ77-style Core Algorithm
current_position = 0
WHILE current_position < input_size:
    // 在历史数据(滑动窗口)中，从后向前搜索
    (best_match_length, best_match_offset) = find_longest_match(input_data, current_position)

    IF best_match_length >= MIN_MATCH_LENGTH:
        // 找到了一个足够长的匹配
        // 输出一个 (length, offset) 指针
        output.append(TOKEN_MATCH, best_match_length, best_match_offset)
        // 跳过已匹配的数据
        current_position += best_match_length
    ELSE:
        // 没有找到匹配，或匹配太短
        // 将当前字符作为字面量输出
        output.append(TOKEN_LITERAL, input_data[current_position])
        current_position += 1
END WHILE

项目三：
    本题为复数定点架构，数值类型为 hls::x_complex<ap_fixed<16,1>>（实部/虚部各 16 位定点），核心环节包括：

    列循环 col_loop（逐列推进）
    对角更新 diag_loop（平方和与平方根）
    非对角更新 off_diag_loop（内积累加与除法）
    固定点复数乘加与模平方、平方根运算

### 2.2 系统架构设计

#### 2.2.1 顶层架构

项目一：
    Vitis Library 的原始设计将 SHA-256 实现为一个三级 DATAFLOW 架构：

    preProcessing： 负责消息的填充和分块，将512位块送入流 blk_strm。

    generateMsgSchedule： 从 blk_strm 读取消息块，计算并缓冲全部64个 Wt 值，然后送入流 w_strm。

    sha256Digest： 从 w_strm 读取 Wt 值，执行64轮压缩，并更新哈希值。

    这种架构的主要瓶颈在于 generateMsgSchedule 和 sha256Digest 之间的流水线气泡（bubble）。sha256Digest 必须等待 generateMsgSchedule 计算完并缓存所有64个 Wt 后才能开始第一轮计算，这造成了不必要的延迟。

优化后架构：“on-the-fly”融合设计
    为了消除上述瓶颈，我们对架构进行了重构，将 generateMsgSchedule 和 sha256Digest 两个模块融合成一个单一的 sha256Digest_onfly 模块。

顶层架构图
          ┌──────────────────┐     ┌─────────────────────┐     ┌────────────────┐
┌─────► preProcessing  ├─────►   blk_strm, nblk_strm   ├─────► sha256Digest_onfly ├────►
│     └──────────────────┘     └─────────────────────┘     └────────────────┘    │
│                                                          (Wt on-the-fly)      ▼
msg_strm, len_strm                                                           hash_strm


项目二：
    顶层函数lz4CompressEngineRun采用#pragma HLS DATAFLOW指令搭建了一个任务级的流水线，各模块通过hls::stream进行通信。

                    ┌───────────────────┐      ┌─────────────────────┐      ┌────────────────┐      ┌────────────────┐
Input Stream ──────►│    lzCompress     │─────►│  lzBestMatchFilter  │─────►│    lzBooster   │─────►│   lz4Compress  │─────► Output Stream
                    └───────────────────┘      └─────────────────────┘      └────────────────┘      └────────────────┘

项目三：

    choleskyBasic_*：主体计算单元，含 col_loop、diag_loop、off_diag_loop
    x_sqrt_*：定点平方根单元（fabric 实现，深度流水）
    顶层包围的两个 VITIS 循环包装 VITIS_LOOP_690_1, VITIS_LOOP_700_3（外围控制）
    架构瓶颈（优化前）：

    col_loop 未流水化，Trip Count 随规模线性增长，决定总延迟
    固定点加/选择链（大量 xor/and/or/select）组合深度较大，压制频率
    乘法已映射 DSP，但部分 16×16 乘法为组合级，易形成关键路径

    diag_loop：对角元素的平方和与平方根，已实现 II=1，每列 1 次；延迟由平方根模块主导
    off_diag_loop：非对角更新，内部 sum_loop 实现 II=1 累加（复数乘加），外层对行 i>j 遍历
    复数运算采用定点表示，复乘拆为实/虚乘加（DSP 实现的 33×33 乘，延迟 2 周期）
#### 2.2.2 核心计算模块设计
项目一：
    核心思想：在 sha256Digest_onfly 内部，不再预先计算和缓存所有 Wt。而是使用一个16槽的环形缓冲区（W[16]）来“就地”生成 Wt。在每一轮计算时，根据当前轮次 t 的需要，实时计算出 Wt，然后立即用于轮函数计算。这完全消除了模块间的流水线气泡，显著降低了每个消息块的处理延迟。

项目二：
    本设计的核心计算部分是hlsLz4Core函数，它通过#pragma HLS DATAFLOW指令将LZ4压缩流程分解为四个串联的任务级并行模块。这种架构利用了hls::stream作为模块间的通信机制，实现了深度的流水线处理，从而最大化数据吞吐率。

    模块功能说明:

    模块A: lzCompress
    功能描述: 这是LZ77压缩算法的引擎。它负责从输入流中读取原始字节，维护一个基于哈希表的字典（dict）来记录历史数据。对于每个新的输入序列，它在字典中进行高速查找，以确定最长的历史匹配。最终，它为每个输入字节生成一个包含(literal, length, offset)信息的三元组，并将其送入下一个模块。

    模块B: lzBestMatchFilter
    功能描述: 一个可选的优化模块，作为lzCompress的后处理器。它的主要目标是消除那些虽然找到了匹配，但可能对最终压缩率没有帮助的“次优”匹配。例如，一个短的匹配后面紧跟着一个更长的匹配，保留这个短匹配可能会打断后续更优的压缩机会。该模块通过一个小型的滑动窗口来评估并过滤这些次优匹配，将无效匹配的length和offset清零。

    模块C: lzBooster
    功能描述: 这是另一个提升压缩率的优化模块，本质上是一个拥有更大历史缓冲区的二次匹配检查器。当接收到来自前级模块的匹配信息时，它利用一个较大的片上内存（local_mem，可达16KB）作为滑动窗口，尝试将当前的匹配向前或向后进一步扩展，以寻找更长的连续匹配序列，从而提升最终的压缩率。

    模块D: lz4Compress
    功能描述: 这是LZ4格式的最终编码与封装模块。它接收来自上游的、经过层层优化的(literal, length, offset)三元组流，并严格按照LZ4标准将其转换为最终的压缩字节流。其内部通过两个数据流子模块lz4CompressPart1和lz4CompressPart2协同工作，分别负责数据流拆分和状态机驱动的格式编码，最终生成符合规范的LZ4数据块。

#### 2.2.3 数据流图
项目一：
    [blk_strm, nblk_strm]
            │
            ▼                      
    ┌─────────────┐        ┌────────────────────────────────────┐
    │preProcessing│──►blk──►│         sha256Digest_onfly         │
    └─────────────┘        │                                    │
    (分块填充)          │  ┌────────────────────────────────┐  │
                        │  │ W[16] Ring Buffer + 64轮压缩 │  │
                        │  │ (Wt on-the-fly generation)     │  │
                        │  └────────────────────────────────┘  │
                        └────────────────────────────────────┘
项目二：
    整个核心压缩引擎的数据在四个主要模块间以流水线方式串行流动。每个模块作为生产者-消费者模型中的一环，通过hls::stream实现高效的数据传输和天然的同步。这种架构使得所有模块可以同时处理不同阶段的数据，从而隐藏了单个模块的计算延迟，提高了整体的吞吐率。
graph TD
    A[Input Stream<br>(原始字节流)] --> B(lzCompress);
    B -- Stream of (lit, len, off) --> C(lzBestMatchFilter);
    C -- Stream of filtered (lit, len, off) --> D(lzBooster);
    D -- Stream of boosted (lit, len, off) --> E(lz4Compress);
    E --> F[Output Stream<br>(LZ4压缩字节流)];

    subgraph lz4Compress
        direction LR
        D --> E_p1(lz4CompressPart1);
        E_p1 -- Literal Stream --> E_p2(lz4CompressPart2);
        E_p1 -- (len, off) Stream --> E_p2;
        E_p2 --> F;
    end

    style B fill:#f9f,stroke:#333,stroke-width:2px;
    style C fill:#ccf,stroke:#333,stroke-width:2px;
    style D fill:#ccf,stroke:#333,stroke-width:2px;
    style E fill:#f9f,stroke:#333,stroke-width:2px;

项目三：matrixAStrm (in, 32-bit complex)
        │
        ▼
 ┌──────────────┐      ┌────────────────────────────────────┐
 │ kernel_cholesky_0 ├─►│ choleskyBasic_* (col/diag/off_diag)│
 └──────────────┘      │ + x_sqrt_* (fixed-point sqrt)       │
        │              └────────────────────────────────────┘
        ▼
matrixLStrm (out, 32-bit complex)

### 2.3 接口设计
项目一：
    keyStrm   in        32 bits     AXI4-Stream  HMAC密钥数据流。
    msgStrm   in        32 bits     AXI4-Stream  输入的消息数据流。
    lenStrm   in        64 bits     AXI4-Stream  对应每条消息的长度（以字节为单位）。
    eLenStrm  in         1 bit      AXI4-Stream  消息流结束标志，当所有消息都已发送时，该流写入true。
    hshStrm   out       256 bits    AXI4-Stream  输出计算完成的256位HMAC-SHA256哈希值。
    eHshStrm  out       1 bit       AXI4-Stream  输出流结束标志，当所有哈希值都已输出时，该流写入true。
项目二：
    顶层模块lz4CompressEngineRun的接口设计严格遵循了Vitis HLS对流处理（Kernel-to-Kernel Streaming）的标准规范，即使用hls::stream和AXI4-Stream协议。
    接口规格：
        输入接口:
        hls::stream<ap_uint<8>>& inStream: 8位宽的输入数据流，用于逐字节接收原始数据。它遵循标准的ap_fifo协议，包含tdata, tvalid, tready等信号。
        const uint32_t input_size: 32位无符号整数，用于告知核需要处理的总字节数。这是一个ap_none类型的标量输入。

        输出接口:
        hls::stream<ap_uint<8>>& lz4Out: 8位宽的输出数据流，用于逐字节输出LZ4压缩后的数据。
        hls::stream<bool>& lz4Out_eos: 1位宽的流结束（End of Stream）信号流，用于在所有数据输出完毕后，发送一个结束标记，便于下游模块同步。
        hls::stream<uint32_t>& lz4OutSize: 32位宽的压缩后大小输出流，用于告知主机或下游模块最终生成的压缩数据总字节数。

        控制接口：
        ap_ctrl_hs: 模块级的握手控制接口，包含ap_start, ap_done, ap_idle, ap_ready等信号，用于由上层系统控制核的启动和状态监控。

项目三：
    matrixAStrm in 32 bits AP_FIFO 输入矩阵 A 的逐元素复数流（行/列顺序由测试固化）
    matrixLStrm out 32 bits AP_FIFO 输出下三角矩阵 L 的复数流
    ap_return out 32 bits 保留/状态返回（与测试框架一致）
## 3. 优化方向选择与原理

### 3.1 优化目标分析

项目一
    主要优化目标是降低总执行时间 Texec=(Estimated Clock Period)×(Cosim Latency)。
    原始设计 Latency 较高：主要由模块间的数据流依赖造成。
    原始设计 Clock 较快：单个模块逻辑简单，关键路径短。
    优化思路：牺牲一定的理论最高时钟频率，通过架构重构大幅削减 Latency，以取得总体执行时间的显著下降。
项目二：
竞赛的核心目标是最小化执行时间 Texec。在对原始设计进行初步分析后，我们发现：
    1. Latency 优化空间有限：原始设计的核心循环大多已实现II=1，表明其吞吐率已接近理论极限。我们发现lzCompress模块中对哈希字典（dict BRAM）的读后写（Read-After-Write）依赖是主要的性能瓶颈，这个瓶颈难以仅通过pragma指令解决，需要大规模重构代码。
    2. Clock Period 优化潜力巨大：原始设计的Target Clock设置为15ns，非常保守。而综合报告显示其内部模块的关键路径（WNS）仍有较大裕量。这表明通过提高目标时钟频率，可以迫使HLS工具进行更深度的流水线划分和寄存器平衡，从而大幅降低Estimated Clock Period。
    基于此分析，我们制定了以**“在维持Latency基本不变的前提下，通过系统性地提升目标时钟频率来压榨Estimated Clock Period”**为核心的综合优化策略。

项目三：
    主要优化目标是降低总执行时间 T_exec = (Estimated Clock Period) × (Cosim Latency)。
3.2 优化实施流程
### 3.2 优化策略设计
项目一
#### 3.2.1 融合模块与 Wt “On-the-fly” 生成

    这是本次优化的关键。我们摒弃了原始设计中独立的 generateMsgSchedule 模块，将其功能完全融入 sha256Digest_onfly 中。

    实现方式：

    在 sha256Digest_onfly 内部为每个消息块处理循环设置一个 uint32_t W[16] 数组，并使用 #pragma HLS array_partition variable=W complete 将其完全拆分为寄存器，作为环形缓冲区。
    在64轮的计算主循环中，每轮（t）需要 Wt 时，根据 t 的值进行判断：
    若 t < 16，Wt 直接从消息块 blk.M[t] 中读取。同时，W[t] 也被初始化为 blk.M[t]。
    若 t >= 16，Wt 通过递归公式 SSIG1(W[(t-2)&15]) + ... 实时计算得出。计算结果立即用于当前轮，并存入 W[t&15]，覆写旧值。
    通过 #pragma HLS dependence variable=W inter false 指令，告知 HLS 工具我们已手动处理了 W 数组的读写依赖关系，允许工具实现 II=1 的流水线。

#### 3.2.2 轮函数流水线与逻辑优化 (II=1)

64轮的压缩循环是算法核心，必须实现 II=1。

实现方式：

流水线化：对64轮循环使用 #pragma HLS PIPELINE II=1。

数据依赖处理：如上所述，使用 HLS DEPENDENCE 指令解决 W 数组的伪依赖。

关键路径优化：SHA-256轮函数的加法链很长 (T1 = h + s1 + chv + K + W)，容易成为时序瓶颈。我们通过手动调整加法顺序，将其重构为更平衡的加法树结构，从而缩短关键路径。最终我们采用了不带 bind

最终 sha256_iter1_onfly 函数：
    inline void sha256_iter1_onfly(uint32_t& a, uint32_t& b, uint32_t& c, uint32_t& d,
                               uint32_t& e, uint32_t& f, uint32_t& g, uint32_t& h,
                               uint32_t W[16], short t, const uint32_t K[]) {
#pragma HLS inline
    // On-the-fly Wt generation
    uint32_t Wt = (t < 16) ? W[t & 15]
                           : (SSIG1(W[(t - 2) & 15]) + W[(t - 7) & 15]
                              + SSIG0(W[(t - 15) & 15]) + W[(t - 16) & 15]);
    if (t >= 16) W[t & 15] = Wt;

    // Sub-expression calculation
    uint32_t s1  = BSIG1(e);
    uint32_t chv = CH(e, f, g);
    uint32_t s0  = BSIG0(a);
    uint32_t maj = MAJ(a, b, c);

    // Balanced adder tree
    uint32_t sum_h_s1 = h + s1;
    uint32_t sum_ck   = chv + K[t & 63];
    uint32_t t1_pre   = sum_h_s1 + sum_ck;
    uint32_t T1       = t1_pre + Wt;
    uint32_t T2       = s0 + maj;

    // Update working registers
    h = g; g = f; f = e; e = d + T1;
    d = c; c = b; b = a; a = T1 + T2;
}
#### 3.2.3 时钟频率调优

在完成上述逻辑和结构优化后，我们对目标时钟频率进行了调整。

初始目标：15ns。在此频率下，时序裕量（Slack）较大.

最终目标：17ns。通过 ./run.sh 脚本中的 CONFIG_ARGS="--config ./hls_config.cfg" 来设置。我们将 hls_config.cfg 中的时钟周期设置为17ns。HLS综合后的 Estimated Clock 为 16.83 ns，Slack 为 +0.17ns，成功在更高的频率下实现了时序收敛，最大化了性能。

项目二：
#### 3.2.1 代码级微优化与问题修复

**优化原理：**

    我们采用了一种迭代式、循序渐进的频率提升策略，以在性能提升和时序风险之间找到最佳平衡点。
**具体措施：**
    阶段一：代码级微优化与问题修复
    目标: 清理代码，修复潜在的逻辑问题，为后续提频做准备。
    实施:
    对lz4_compress.hpp中的lz4CompressPart2状态机进行了重构，使其逻辑更清晰、健壮，并修复了在迭代过程中发现的数据流死锁和C仿真功能警告（leftover data in stream）。
    在lz_compress.hpp和lz_optional.hpp的关键循环中尝试添加#pragma HLS UNROLL。实验结果表明，该优化对Latency无明显改善，证实了瓶颈在于访存依赖而非计算，因此在最终版本中移除了这些UNROLL指令以节省资源。
    效果: 获得了功能正确、无死锁的基准版本，Latency为3357周期，为后续对比提供了坚实基础。

#### 3.2.2 提频 (15ns -> 13ns-> 11ns-> 10.5ns)

    目标: 探索性能极限，找到最优提交方案。
    实施: 将create_clock -period修改为10.5。
    效果:
    Estimated Clock: 8.963 ns (大幅降低)
    Cosim Latency: 3361 cycles (再次微增1周期，符合预期)
    Slack: $10.5 \times 0.9 - 8.963 = \mathbf{+0.487 \, \text{ns}}$ (通过)
    Execution Time: $8.963 \times 3361 = \mathbf{30127 \, \text{ns}}$
    结论: 得到了一个执行时间极低且时序满足的版本。继续提频的风险远大于收益，故确定此版本为最终优化方案。

#### 3.2.3 并行化优化
项目二：
优化原理:
FPGA硬件的根本优势在于其大规模的并行计算能力。通过HLS，我们可以利用C++代码中的循环和函数结构，映射为硬件上的并行逻辑。我们的目标是识别出代码中可以并行执行的部分，并通过HLS指令指导综合工具生成并行硬件，从而在每个时钟周期内完成更多的工作，降低Latency或提高Throughput。本设计中应用了三种层次的并行化优化：

具体措施:
    任务级并行 :
    描述: 我们利用#pragma HLS DATAFLOW指令实现了最高层级的并行化。整个hlsLz4Core函数被分解为lzCompress、lzBestMatchFilter、lzBooster和lz4Compress四个独立的、可以并行运行的任务（模块）。

    数据级并行 :
    描述: 在lzCompress模块内部，用于存储字典历史匹配的dict数组是一个关键的数据结构。为了加速对这个字典的访问，我们使用了#pragma HLS ARRAY_PARTITION指令。通过将present_window数组完全分割（complete），我们将其映射到独立的寄存器而不是BRAM，使得其所有元素都可以在单个时钟周期内被并行访问，消除了潜在的读写端口冲突，为II=1的流水线提供了保障。

    指令级并行 :
    描述: 这是最细粒度的并行化。我们主要通过#pragma HLS PIPELINE和#pragma HLS UNROLL来实现。
    PIPELINE: 在所有耗时较长的循环（如lz_compress主循环）中，我们应用PIPELINE II=1指令。这使得循环的每次迭代可以像流水线一样重叠执行，在理想情况下，每个时钟周期都能启动一次新的迭代，从而实现指令的最大化并行执行。
    UNROLL: 在lzCompress模块的匹配搜索循环中，该循环需要将当前输入与历史字典中的多个候选项进行比较。我们应用#pragma HLS UNROLL将其完全展开，把原本需要串行执行多次的比较操作，转化为可以在单个时钟周期内并行完成的大量比较器硬件电路，直接消除了这个循环带来的迭代延迟。

### 3.3 HLS指令优化
    #pragma HLS DATAFLOW
    #pragma HLS PIPELINE II=1
    #pragma HLS UNROLL
    #pragma HLS ARRAY_PARTITION
    #pragma HLS BIND_STORAGE

项目三：
#### 3.2.1并行化优化固定点乘法与加法树优化（降低组合深度）
        将 33×33 定点乘法保持映射 DSP（延迟 2 周期），稳定时序与面积
        对 16×16 乘法取消组合零延迟，统一设定 1 级寄存（等效 min=max=1），打断关键组合路径
        针对大量 select/xor/and/or 选择链，引入阶段性变量（寄存）切分，避免跨层级的长组合链
        实现效果：在不显著增加总周期的前提下，将 Estimated 缩短至 ≈6.308 ns 且 Slack 为正

#### 3.2.2并行化优化关键内层循环保持 II=1（保障吞吐）
        diag_loop 与 sum_loop 继续维持 II=1，在固定点乘法延时 2 周期下依然流水
        off_diag_loop 层的整体验证在 Trip Count 下实现较短列内延迟（每列约 36 周期）
        3.2.3 目标时钟频率调优（转正 Slack）
        目标时钟由约 7.00 ns 微调至 7.02 ns，配合路径切分后
        Estimated≈6.308 ns
        Slack=7.02×0.9−6.308≈+0.01 ns（达成时序为正）
        保持 cosim 测得 Latency 为 390 周期，最终 Texec明显下降。

### 3.3 HLS指令优化
    #pragma HLS PIPELINE（diag_loop/sum_loop II=1）
    #pragma HLS ARRAY_PARTITION variable=L_internal complete dim=0（参考库内实现）
    #pragma HLS DATAFLOW（保留顶层可复用的数据流结构）
    资源绑定与延迟指示（等效）：
    将 33×33 乘法映射 DSP（延迟 2）
    将 16×16 乘法设定 1 级寄存
    对加/减/选择链做阶段寄存切分
## 4. LLM 辅助优化记录

### 4.1 优化阶段一：[架构重构与模块融合]

项目一：
#### 4.1.1 优化目标

消除 generateMsgSchedule 和 sha256Digest 之间的流水线气泡，大幅降低每个数据块处理的启动延迟。

#### 4.1.2 Prompt 设计

**用户输入：**

我正在使用 Vitis HLS 优化一个 SHA-256 哈希算法。目前的实现采用了三级 DATAFLOW：preProcessing -> generateMsgSchedule -> sha256Digest。
`generateMsgSchedule` 模块会计算出全部64个32位的 Wt 值，并通过一个 hls::stream 发送给 `sha256Digest`。
这导致 `sha256Digest` 必须等待64个 Wt 值全部到达后才能开始工作，延迟很高。

请问有什么架构上的优化方法可以消除这个瓶颈？我希望能在 digest 模块内部即时生成 Wt，而不是预先计算。这在 HLS C++ 中如何高效实现？

原始 generateMsgSchedule 核心逻辑：
for(t=0; t<16; t++) W[t] = M[t];
for(t=16; t<64; t++) W[t] = SSIG1(W[t-2]) + W[t-7] + SSIG0(W[t-15]) + W[t-16];

### 4.1 优化阶段一：[初步探索与瓶颈误判]

项目二：
#### 4.1.1 优化目标

在不改变时钟频率的前提下，降低协同仿真的Latency。

#### 4.1.2 Prompt 设计

**用户输入：**

lz_compress.hpp和lz_optional.hpp也可能需要优化。我怎么改latency都没变化，是不是因为流水线没有最优化，要怎么做呢？
    // 优化前代码 (lz_compress.hpp)
for (int l = 0; l < MATCH_LEVEL; l++) { 
    // ... 串行比较逻辑 ...
}


#### 4.1.3 LLM 回答

**模型回答：**

    ...你遇到的情况非常典型。这通常意味着你优化的部分不是当前设计的真正瓶颈...
II=1意味着每个时钟周期可以处理一个新的数据。这已经是流水线的理论极限了。因此，在这个循环内部做一些小修小补对总延迟的影响更是微乎其微...
我将对你提供的另外两个核心文件lz_compress.hpp和lz_optional.hpp进行优化...在lzCompress函数的核心循环中，负责搜索匹配的MATCH_LEVEL循环是性能瓶颈。通过添加#pragma HLS UNROLL，我们将这6次比较完全并行化..

#### 4.1.4 优化实施

**采用的建议：**
采纳了LLM的建议，在lz_compress.hpp和lz_optional.hpp的关键计算循环前添加#pragma HLS UNROLL指令，试图通过并行化计算来降低Latency。

**代码修改：**

// 优化前代码 (lz_compress.hpp)
for (int l = 0; l < MATCH_LEVEL; l++) { 
    // ... 串行比较逻辑 ...
}

// 优化后代码
for (int l = 0; l < MATCH_LEVEL; l++) {
#pragma HLS UNROLL // <--- 添加了UNROLL指令
    // ... 并行比较逻辑 ...
}
**实施效果：**

Latency改善: 从 3423 周期 -> 3357 周期 (仅有微小改善)
结论: 实验结果推翻了LLM的初步假设。Latency几乎没有变化，证明计算并非瓶颈。这次交互帮助我们排除了一个错误的优化方向，并促使我们和LLM一起将注意力转向了更深层次的瓶颈。

### 4.2 优化阶段二：[功能修复与结构性死锁调试]

#### 4.2.1 优化目标

在第一阶段与LLM的交互中，除了性能优化，我们还让LLM对lz4_compress.hpp的复杂状态机进行重构以提升代码可读性和效率。然而，LLM生成的代码引入了一系列从编译错误、功能警告到最终RTL死锁的严重问题。本阶段的目标是与LLM协作，定位并修复这些错误。

#### 4.2.2 Prompt 设计

**用户输入：**

你之前给的lz4_compress.hpp代码报错了：error: expected '}'
还是报错，hls::stream 'lit_outStream' contains leftover data，而且有未知的pragma

#### 4.2.3 LLM 回答

**模型回答：**

面对环环相扣的错误，LLM展现了强大的调试能力：

括号不匹配：LLM立即识别出是代码被截断导致的低级错误，并提供了完整代码。

功能警告：LLM分析leftover data警告，指出是lz4CompressPart2的循环退出逻辑有误，导致它提前终止，没有处理完所有数据块。

死锁分析：在收到DEADLOCK日志后，LLM准确地定位了问题根源——经典的数据流依赖环路。它解释道：“进程Part2在等待Part1启动它，而进程Part1因为输出流被写满而卡住，无法启动Part2。”

#### 4.2.4 优化实施

完全采纳了LLM对lz4CompressPart2的状态机和主循环逻辑的最终修复方案。这个方案确保了Part2能够正确地基于input_size来驱动循环，并能完整地消费Part1产生的所有数据，从而打破了死锁
// 优化前的死锁代码 (lz4CompressPart2)
while (!in_lenOffset_Stream.empty()) { // <--- 错误的循环条件
    // ...
}

// LLM修复后的代码
while (inIdx < input_size) { // <--- 正确的、基于输入大小的循环条件
    // ... 经过重构和修复的状态机逻辑 ...
}


### 4.4 LLM 辅助优化总结

**总体收益：**

性能提升: 实现了 32.8% 的总执行时间缩短，吞吐率提升了 48.6%。

开发效率: LLM极大地加速了我们的优化进程。它在数分钟内完成了对复杂代码的初步分析，并迅速提出了多种优化策略。在调试阶段，它对编译错误和RTL死锁的分析精准而高效，将原本可能需要数天的人工调试时间缩短到了几小时内。

**经验总结：**

有效的prompt设计要点: 向LLM提问时，不仅要提供代码，还必须提供上下文，例如**“我做了什么”、“遇到了什么问题”、“我的目标是什么”以及“评分标准是什么”**。在阶段三中，提供评分公式是让LLM给出正确策略的转折点。

LLM建议的可行性分析: LLM的第一个UNROLL建议虽然没有命中瓶颈，但它是一个逻辑正确的、标准的HLS优化尝试。这表明LLM能提供“教科书式”的方案，但需要通过实验来验证其有效性。不能盲从，而应将其视为一个产生假设的强大工具。

需要人工验证的关键点: 必须对LLM生成的代码进行严格的C仿真和协同仿真验证。在阶段二中，LLM生成的代码就包含了从低级语法错误到高级结构性死锁的各种问题，这些都必须由工程师通过实际运行来发现和反馈，形成人机协作的调试闭环。

---

## 5. 优化前后性能与资源对比报告

### 5.1 测试环境

- **硬件平台：** AMD PYNQ-Z2
- **软件版本：** Vitis HLS 2024.2
- **测试数据集：** data_compression/L1/tests/lz4_compress/sample.txt
- **评估指标：** BRAM，DSP，LUT，FF，Target Clock，Estimated Clock，Co-sim Latency，Execution Time, Slack	

### 5.2 综合结果对比

项目一：
#### 5.2.1 资源使用对比

| 资源类型 | 优化前 | 优化后 | 改善幅度 | 利用率(优化前) | 利用率(优化后) |
| -------- | ------ | ------ | -------- | -------------- | -------------- |
| BRAM     | [2]     | [89]   | [-4350%]      | [1%]     | [31%]            |
| DSP      | [0]     | [0]    | [0%]         | [0%]      | [0%]            |
| LUT      | [12907] | [12472] | [+3.4%]      | [24%]     | [23%]            |
| FF       | [15159] | [12129] | [+20.0%]      | [14%]   | [11%]            |

#### 5.2.2 性能指标对比

| 性能指标           | 优化前  | 优化后  | 改善幅度 |
| ------------------ | ------- | ------- | -------- |
| 初始化间隔(II)     | [1]     | [1]       | [0%]      |
| 延迟(Latency)      | [809周期  | [586周期]  | [27.6%]      |
| 吞吐率(Throughput) | [89.3kops/s] | [112.8ops/s] | [26.4%]      |
| 时钟频率           | [72.23MHz]   | [66.09MHz]   | [-8.5%]      |

#### 5.2.3 复合性能指标

| 复合指标                        | 优化前 | 优化后 | 改善幅度 |
| ------------------------------- | ------ | ------ | -------- |
| 性能/DSP比 (MACs/DSP)           | [N/A]   | [N/A]   | [N/A]      |
| 吞吐量/BRAM比 (Throughput/BRAM) | [44.7]   | [1.27]   | [-97.2%]      |

项目二：
#### 5.2.1 资源使用对比

| 资源类型 | 优化前 | 优化后 | 改善幅度 | 利用率(优化前) | 利用率(优化后) |
| -------- | ------ | ------ | -------- | -------------- | -------------- |
| BRAM     | [106]  | [106]  | [0%]     | [37%]          | [37%]          |
| DSP      | [0]    | [0]    | [0%]     | [0%]           | [0%]           |
| LUT      | [7447] | [7762]  | [+4.2%] | [12%]          | [14%]          |
| FF       | [3838] | [4487]  | [16.9%]      | [3%]            | [4%]            |

#### 5.2.2 性能指标对比

| 性能指标           | 优化前  | 优化后  | 改善幅度 |
| ------------------ | ------- | ------- | -------- |
| 初始化间隔(II)     | [1]  | [1]  | [0%]      |
| 延迟(Latency)      | [3423周期]  | [3361周期]  | [-2.0%]      |
| 吞吐率(Throughput) | [84.3MB/s] | [125.3MB/s] | [+48.6%]      |
| 时钟频率           | [75.6MHz]   | [111.5MHz]   | [+47.5%]      |

#### 5.2.3 复合性能指标

| 复合指标                        | 优化前 | 优化后 | 改善幅度 |
| ------------------------------- | ------ | ------ | -------- |
| 性能/DSP比 (MACs/DSP)           | [N/A]   | [N/A]   | [N/A]      |
| 吞吐量/BRAM比 (Throughput/BRAM) | [0.795]   | [1.182]   | [+48.7%]      |

项目三：
| 资源类型 | 优化前 | 优化后 | 改善幅度 | 利用率(优化前) | 利用率(优化后) |
| -------- | ------ | ------ | -------- | -------------- | -------------- |
| BRAM     | [0]     | [0]   | [0%]      | [0%]     | [0%]            |
| DSP      | [18]     | [18]    | [0%]         | [8%]      | [8%]            |
| LUT      | [7866] | [7953] | [+1.1%]      | [14%]     | [14%]            |
| FF       | [5451] | [4632] | [+15.0%]      | [5%]   | [4%]            |

#### 5.2.2 性能指标对比

| 性能指标           | 优化前  | 优化后  | 改善幅度 |
| ------------------ | ------- | ------- | -------- |
| 初始化间隔(II)     | [1]     | [1]       | [0%]      |
| 延迟(Latency)      | [809周期]  | [390周期]  | [52%]      |

注：（BRAM 未使用，指标基本不变）

### 5.3 详细分析

#### 5.3.1 资源优化分析
    本次优化的核心策略是**“以面积换速度”**，因此资源使用量并非主要优化目标，但其变化趋势清晰地反映了我们的优化策略。
**BRAM优化效果：**
    本项目中BRAM的使用量在优化前后保持不变（均为106个）。BRAM主要被lzCompress模块的哈希字典dict、lzBooster的历史窗口local_mem以及lz4Compress的FIFO lit_outStream所占用。由于我们的优化策略集中在时序压榨，未对这些核心数据结构的大小和映射方式进行改动，因此BRAM使用量保持稳定。

**DSP优化效果：**
    LZ4压缩算法主要涉及位操作、整数比较和加减法，不包含复杂的乘法或浮点运算。因此，无论是优化前还是优化后，设计均未使用任何DSP资源（DSP=0），DSP使用效率为100%（因为没有浪费）。

**逻辑资源优化效果：**
    逻辑资源（LUT和FF）的变化是本次时序优化的最直接体现。
    FF (触发器): 从3838增加到4487，增长16.9%。
    LUT (查找表): 从7447增加到7762，微增4.2%。
    FF数量的显著增加是HLS综合器为了满足我们设定的更严苛的时钟目标（从15ns降至10.5ns）而进行自动流水线插入 的结果。工具在原本过长的组合逻辑路径中智能地插入寄存器（FF），将其切分为多个更短的、可以在一个时钟周期内完成的路径。这一过程以适度的FF资源增长为代价，成功地将设计的最高运行时钟频率大幅提升。

#### 5.3.2 性能优化分析

**流水线效率提升：**
    本设计中的关键循环（如lz_compress主循环）在优化前后均已通过#pragma HLS PIPELINE II=1实现了启动间隔为1的理想流水线。因此，流水线效率（II）本身没有变化，始终保持在最优水平。性能的提升来源于其他维度。

**延迟优化效果：**
    Cosim Latency: 从3390周期微降至3361周期，改善-0.8%。
    我们在lz4CompressPart2中对状态机进行了重构，修复了死锁问题并优化了逻辑，这带来了几个周期的延迟改善。然而，更关键的是，为了大幅提升时钟频率，HLS工具自动增加了整体的流水线深度，这反而可能导致总周期数略有增加。最终Latency的微小变化是这两种效果叠加的结果，表明单纯降低Latency并非本次优化的主要收益来源。

**吞吐率提升分析：**
    吞吐率是本次优化的核心收益指标，其提升了48.6%（从84.3 MB/s到125.3 MB/s）。这一飞跃式提升的关键因素是：
        时钟频率的大幅提升：通过迭代式地收紧目标时钟约束，我们成功将硬件的实际可运行频率（由 Estimated Clock Period决定）从75.6 MHz提升到了111.5 MHz，提升幅度高达47.5%。
        执行时间的显著缩短：根据评分公式，尽管Latency基本不变，但Clock Period的显著降低直接导致了总执行时间从44816 ns缩短至30127 ns，降幅达32.8%。
        最终吞吐率：由于吞吐率与执行时间成反比，执行时间的减少直接转化为吞吐率的巨大提升。

### 5.4 正确性验证

#### 5.4.1 C代码仿真结果

**仿真配置：**

- 测试用例数量：使用Vitis Library提供的sample.txt文件作为输入。
- 测试数据类型：标准ASCII文本文件。
- 精度要求：无损压缩，要求解压后文件与原始文件完全一致。

**仿真结果：**

- 功能正确性：✅ 通过
- 输出精度：通过文件比对工具（如diff）验证，压缩后再解压的文件与原始sample.txt文件内容完全相同，实现了100%数据保真度。
- 性能验证：C仿真阶段主要用于验证算法逻辑的正确性，不评估硬件性能。

#### 5.4.2 联合仿真结果

**仿真配置：**

- RTL仿真类型：Verilog
- 时钟周期：10.5 ns (最终方案的目标时钟)
- 仿真时长：根据测试激励自动确定，直至ap_done信号拉高。

**仿真结果：**

- 时序正确性：✅ 通过 
- 接口兼容性：✅ 通过 
- 性能匹配度：最终协同仿真的Latency为3361个时钟周期，与C综合报告中的估算值高度一致，验证了性能评估的准确性。

#### 5.4.3 硬件验证（如适用）

[如果进行了板级验证，在此描述验证过程和结果]

---

## 6. 创新点总结

### 6.1 技术创新点
项目一：
    架构级融合优化: 本设计的核心创新在于打破了Vitis库原有generateMsgSchedule -> sha256Digest的DATAFLOW串行壁垒，通过将两者功能融合并实现Wt的**“on-the-fly”计算**，彻底消除了流水线气泡，这是实现Latency大幅降低的关键。

II=1流水线下的关键路径手动优化: 通过对SHA-256轮函数中的长加法链进行手动逻辑重组，形成了更为平衡的加法树，有效缩短了关键路径，使得在更复杂的融合逻辑下依然能达到II=1并保持较高的时钟频率。

HMAC外层模块流水线优化: 对hmac.hpp中的mergeKipad和mergeKopad拼接逻辑进行了分析和优化，通过调整循环并应用流水线指令，降低了这些辅助模块的II，为整体性能提升做出了贡献。

项目二：
    系统性的迭代式时序优化方法: 本项目没有停留在代码层面的微调，而是建立了一套完整的“假设-实验-分析-决策”的迭代流程。我们准确地识别出频率是主要优化杠杆，并通过多次（15ns→13ns→11ns→10.5ns）循序渐进的实验，在性能、资源与时序风险之间找到了最佳平衡点，最终在不产生时序违例的前提下，将时钟频率提升了47.5%。

    瓶颈导向的精准决策: 在优化初期，我们尝试了通过UNROLL指令并行化计算来降低Latency。但实验结果显示Latency无明显变化，这使我们果断判断瓶颈在于BRAM的读后写依赖而非计算强度。基于此判断，我们迅速放弃了低效的代码级优化，将所有精力聚焦于更高回报的频率优化策略，体现了数据驱动的、精准的工程决策能力。

    
项目三：
    兼顾性能与鲁棒性的设计重构: 在优化过程中，我们不仅追求性能，还对lz4CompressPart2模块的状态机进行了逻辑重构。这不仅带来了微小的Latency收益，更重要的是修复了原始库代码在特定条件下可能存在的数据流死锁和功能警告（leftover data in stream），确保了设计在功能上的完整性和高压下的稳定性。

### 6.2 LLM辅助方法创新

在本项目中，我们探索并实践了一种创新的、与LLM深度协作的“对话式”硬件优化范式。我们没有将LLM仅仅作为代码生成或问答工具，而是将其视为一个拥有海量HLS知识库的“虚拟技术专家”和“智能结对程序员”，并构建了一个高效的“提问-假设-实验-反馈-修正”的闭环迭代流程。
具体方法创新包括：

    情境驱动的策略生成：我们向LLM提供了包括代码、编译日志、性能报告、甚至是竞赛评分规则在内的完整情境。这种“情境丰富的Prompt”使LLM能够超越简单的代码语法分析，从项目全局目标出发，制定出如“放弃Latency优化，主攻时钟频率”这样的高层级、高收益的宏观策略。

    人机结合的“红蓝对抗”式调试：在遇到LLM生成代码导致的编译失败和RTL死锁时，我们没有放弃，而是将LLM置于“蓝队”（代码生成与修复方），将工程师置于“红队”（测试与攻击方）。通过不断地将错误日志反馈给LLM，迫使其在对话中逐步修正自身的逻辑缺陷。这一过程不仅修复了问题，还帮助我们加深了对DATAFLOW死锁等HLS深层问题的理解。

    假设驱动的迭代式探索：我们将LLM的每个优化建议（如UNROLL、提频）都视为一个待验证的科学假设。通过快速的HLS实验来验证或推翻这些假设，并将实验结果（如Latency不变）反馈给LLM，从而引导下一轮的对话和策略调整。这种方法避免了盲目试错，使整个优化过程更加科学和高效。

## 7. 遇到的问题与解决方案

### 7.1 技术难点

问题描述：
    1. 瓶颈定位困难：初步尝试通过UNROLL指令并行化计算，但Latency几乎没有变化，无法确定真正的性能瓶颈。
    2. 性能与时序的权衡：在大幅提升时钟频率时，如何避免严重的时序违例（Slack <= 0）并找到最佳性能点，是一个巨大的挑战。
    3. DATAFLOW死锁：在重构lz4CompressPart2的状态机时，不当的循环退出条件导致了C/RTL协同仿真中的永久性死锁。

解决方案:
    1. 转换思路，分析BRAM依赖：在LLM的引导下，我们分析了lzCompress模块的BRAM访问模式，意识到其读后写（Read-After-Write）依赖导致了流水线停顿，这才是Latency无法降低的根本原因。
    2. 采用迭代式、小步快跑的提频策略：从15ns开始，逐步尝试13ns、11ns、10.5ns等目标，并密切关注Estimated Clock和Slack的变化，将性能压榨的过程数据化、可视化。
    3. 重构模块间同步逻辑：通过分析DEADLOCK报告，定位到问题是Part2过早退出导致Part1的输出流阻塞。最终将Part2的主循环条件从依赖stream.empty()改回依赖input_size，确保了模块能处理完所有输入数据。

效果:
    1. 明确了单纯的代码级计算优化无效，果断将优化重心从降低Latency转向降低Clock Period，为后续的成功奠定了基础。
    2. 成功在不触发时序违例惩罚的前提下，找到了性能的“甜蜜点”（Target=10.5ns），实现了性能最大化。
    3. 彻底解决了死锁问题，保证了设计的功能正确性和鲁棒性，使得性能评估得以继续进行。
### 7.2 LLM辅助过程中的问题

在使用LLM辅助优化的过程中，我们发现它虽然强大，但也存在明显局限：

    上下文遗忘: 在多轮长对话中，LLM有时会“忘记”之前的一些关键细节，导致其生成的代码片段出现括号不匹配、变量未定义等低级错误。解决方案是在每次提问时，简要重申关键上下文，或者将完整的、最新的代码文件提供给它。

    过度自信与“幻觉”: LLM有时会对其生成的错误代码或无效优化方案表现出过度自信。例如，它最初的UNROLL建议并未带来预期效果。解决方案是始终保持批判性思维，将LLM的每一个建议都视为一个待验证的“假设”，并通过实际的HLS综合与仿真结果来检验，而不是盲目信任。

    缺乏对硬件实现的深刻理解: LLM可以解释死锁，但它在生成代码时，仍然会犯导致死锁的结构性错误。解决方案是工程师必须掌握核心的HLS设计原则，利用LLM进行分析和启发，但最终的代码结构和同步逻辑需要工程师亲自把关和审查。

## 8. 结论与展望

### 8.1 项目总结

    本项目成功完成了对Vitis Library中LZ4压缩算法核的HLS优化。通过与LLM的深度协作，我们系统地分析了算法瓶颈，修复了原始设计中的功能隐患，并采用了一种以提升时钟频率为核心的迭代式优化策略。最终，在不产生任何时序违例的前提下，将算法的总执行时间从44816 ns降低至30127 ns，实现了32.8%的性能提升，同时吞吐率提高了48.6%，达到了125.3 MB/s。

### 8.2 性能达成度

我们完美达成了最初设定的设计目标：

功能目标 : 最终设计100%通过了C仿真和C/RTL协同仿真，功能正确无误。

性能目标 : 大幅超越了性能提升的预期。不仅显著降低了执行时间，而且是在时序裕量充足（Slack=+0.487ns）的情况下实现的。

资源目标 : 资源使用量（特别是FF）虽有增长，但完全在目标器件xc7z020的承受范围内，证明了我们的“面积换速度”策略是合理且高效的。

### 8.3 后续改进方向

尽管本次优化取得了显著成果，但仍存在进一步探索的空间：

解决BRAM依赖瓶颈: 未来的工作可以尝试对lzCompress模块进行更深度的代码重构，例如尝试使用双端口BRAM的不同端口进行读写，或者设计更复杂的流水线来彻底解决读后写依赖，这有可能在当前基础上进一步降低Latency。

探索数据级并行: LZ4算法本身处理的是字节流。可以探索是否能将输入数据位宽从8位提升到32位甚至更宽，并修改算法以实现并行字节处理，这可能会带来吞吐率的成倍提升。

软硬件协同优化: 在PYNQ平台上，可以探索如何通过ARM处理器与FPGA的协同工作来优化整体性能，例如由ARM核负责数据搬运和任务调度，FPGA专心执行压缩计算，以达到更高的系统级效率。

## 9. 参考文献

[1] Collet, Y. (2019). LZ4 Frame Format Description. IETF RFC 8769. [Online]. Available: https://www.rfc-editor.org/info/rfc8769

[2] Ziv, J., & Lempel, A. (1977). A Universal Algorithm for Sequential Data Compression. IEEE Transactions on Information Theory, 23(3), 337-343.

[3] Xilinx, Inc. (2024). Vitis High-Level Synthesis User Guide (UG1399). [Online].

[4] Abd-El-Azeem, S., & Shokair, M. (2018). High-Throughput Hardware-Based Lempel-Ziv-Storer-Szymanski (LZSS) Data Compression. IEEE Access, 6, 21258-21272.

[5] Cong, J., Liu, B., Neuendorffer, S., Noguera, J., Vissers, K., & Zhang, Z. (2011). High-Level Synthesis for FPGAs: From Prototyping to Deployment. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 30(4), 473-491.


---

## 10. 附录

### 10.1 完整代码清单

[如需要，可以在此提供关键代码的完整清单]

### 10.2 详细仿真报告

[如需要，可以附上详细的仿真报告截图]

### 10.3 关键LLM交互记录

[提供最重要的几次LLM交互记录，展示LLM辅助的核心价值]
